\documentclass{../mfa}
\sheet{1}
\begin{document}
\maketitle

\section{}
\subsection{}

\renewcommand{\v}[1]{\mbf{v}_{#1}}
Wir nehmen an, $\mbf{v}_1$ und $\mbf{v}_2$ seien linear abhängig. Folglich existieren
$\alpha_1,~\alpha_2 \in \mathbb{K}$, sodass $\alpha_1 \mbf{v}_1 + \alpha_2 \mbf{v}_2 = \mbf{0}$
\begin{align}
   \alpha_1 \mbf{v}_1 + \alpha_2 \mbf{v}_2 &= \mbf{0} & \hspace{1cm} & | \cdot A
   \\
   \alpha_1 A \mbf{v}_1 + \alpha_2 A \mbf{v}_2 &= \mbf{0} \\
   \alpha_1 \lambda_1 \mbf{v}_1 + \alpha_2 \lambda_2 \mbf{v}_2 &= \mbf{0} & & | \mbf{v}_i~\text{Eigenvektoren}
\end{align}

Multipliziert man (1) mit $\lambda_1$, so erhält man 
\begin{align}
   \alpha_1 \lambda_1 \mbf{v}_1 + \alpha_2 \lambda_1 \mbf{v}_2 &= \mbf{0} \\
   \intertext{Subtraktion (3) $-$ (4) ergibt}
   \mbf{0} + (\lambda_2 - \lambda_1)\alpha_2 \mbf{v}_2 &= \mbf{0}
\end{align}
Es muss also entweder (a) $\lambda_1 = \lambda_2$ oder (b) $\alpha_2 = 0$ oder
(c) $\mbf{v}_2 = \mbf{0}$ gelten. (a) gilt nicht nach Aufgabenstellung. (c) gilt nicht aufgrund der
Definition eines Eigenvektors. Wenn $\alpha_2 = 0$, muss aber nach Gleichung (1)
Aauch $\alpha_1 = 0$ sein. Daraus folgt, dass $\mbf{v}_1$ und $\mbf{v}_2$ linear unabhängig sein müssen.

\subsection{}

Da $\mbf{v}_1, \mbf{v}_2$ Eigenvektoren sind, gilt 
\begin{equation*}
   A(\alpha_1 \v{1} + \alpha_2 \v{2}) = \alpha_1 A \v{1} + \alpha_2 A \v{2} =
   \alpha_1 \lambda \v{1} + \alpha_2 \lambda \v{2} = \lambda (\alpha_1 \v{1} + \alpha_2 \v{2})
\end{equation*}
Die Linearkombination ist also Eigenvektor von A.

\subsection{}

In (1) wurde gezeigt, dass zwei Eigenvektoren linear unabhängig sind, wenn ihre
Eigenwerte unterschiedlich sind. Wir beweisen zunächst, dass dies für $n$
unterschiedliche Eigenwerte mit zugehörigen Eigenvektoren gilt.

\begin{proof}

\textbf{Induktionsanfang:} Aussage gilt für $n=2$.

\textbf{Induktionsschritt:} Sei bis $n$ bewiesen. Gegeben seien paarweise
verschiedene Eigenwerte $\lambda_1, \lambda_2, \ldots, \lambda_{n+1}$ und
Eigenvektoren $\v{1}, \v{2}, \ldots, \v{n+1}$, wobei $\v{1}, \ldots, \v{n}$
linear unabhängig sind, nach Vorraussetzung. Wir nehmen an, $\v{n+1}$ wäre
linear abhängig von $\v{1}, \ldots, \v{n}$. Es existieren also Skalare
$\alpha_i$ mit 
\setcounter{equation}{0}
\begin{align}
   \alpha_1 \v{1} + \ldots \alpha_n \v{n} + \alpha_{n+1} \v{n+1} &= \mbf{0} \\
   \intertext{Multiplikation mit $A$ liefert}
   \alpha_1 \lambda_1 \v{1} + \ldots \alpha_n \lambda_n \v{n} + \alpha_{n+1} \lambda_{n+1} \v{n+1} &= \mbf{0} \\
   \intertext{denn $\v{i}$ sind Eigenvektoren. Multiplikation von (1) mit
   $\lambda_{n+1}$ ergibt}
   \alpha_1 \lambda_{n+1} \v{1} + \ldots \alpha_n \lambda_{n+1} \v{n} + \alpha_{n+1} \lambda_{n+1} \v{n+1} &= \mbf{0} \\
   \intertext{Subtraktion (2)$-$(3) ergibt}
   \alpha_1(\lambda_1 - \lambda_{n+1})\v{1} + \ldots + \alpha_n (\lambda_n -
   \lambda_{n+1})\v{n} &= \mbf{0}
\end{align}
Da die $\lambda_i$ unterschiedlich sind und $\v{1}, \ldots, \v{n}$ linear
unabhängig, muss $\alpha_1 = \ldots = \alpha_n = 0$ gelten. Mit (1) folgt
$\alpha_{n+1} = 0$ und alle $\v{i}$ sind linear unabhängig. 
\end{proof}

$A$ hat also $n$ linear unabhängige
Eigenvektoren $\mbf{v}_i$. Nach Satz 11.10 ist $A$ als $B=S^{-1} A S$ diagonalisierbar mit
\begin{equation*}
   S = \begin{pmatrix}
      \mbf{v}_1 \ldots, \mbf{v}_n
   \end{pmatrix}
\end{equation*}

\section{}
\subsection{$A_1$}

Es ist $\chi_{A_1}(\lambda) = det(A_1 - \lambda I) = 
\left|
\begin{pmatrix}
   1-\lambda & 2 \\
   0 & 3 - \lambda
\end{pmatrix}
\right|= (1-\lambda)(3-\lambda)$

$A_1$ hat also Eigenwerte 
\begin{align*}
   \lambda_1 &= 1 \\
   \lambda_2 &= 3 
\end{align*}

Wir berechnen die Eigenvektoren.

$\mbf{\lambda_1:}$
\par 
\begin{align*}
   0x_1 + 2x_2 &= 0 \\
   0x_1 + 2x_2 &= 0
\end{align*}
also ist $x_2 = 0$ und $x_1$ beliebig $\Rightarrow \v{1} = \begin{pmatrix} 1 \\
0 \end{pmatrix}$ oder irgendein Vielfaches. Der Eigenraum zu $\lambda_1$ ist
also der Spann von (die Gerade durch) $\v{1}$ oder $\{\mu \cdot \v{1} \mid \mu
\in \mathbb{K}\}$.

$\mbf{\lambda_2:}$
\par 
\begin{align*}
   -2x_1 + 2x_2 &= 0 \\
   0          &= 0 \\
   \intertext{Es folgt}
   x_1        &= x_2
\end{align*}
$\Rightarrow \v{2} = \begin{pmatrix} 1 \\ 1 \end{pmatrix}$. Der Eigenraum zu
   $\lambda_2$ ist $\{\mu \cdot \v{2} \mid \mu \in \mathbb{K}\}$

\subsection{$A_2$}

Es ist $\chi_{A_2}(\lambda) = det(A_2 - \lambda I) = 
\left|
\begin{pmatrix}
   3-\lambda & 2 \\
   -2 & -2 - \lambda
\end{pmatrix}
\right|= (3 - \lambda)(-2 - \lambda) + 4 = \lambda^2 - \lambda -2$. Die
pq-Formel liefert hierfür
\begin{align*}
   \lambda_{1,2} & = \frac{1}{2} \pm \sqrt{\frac{1}{4} + 2} \\
   \lambda_1     & = 2                                        \\
   \lambda_2     & = -1                                       \\
\end{align*}

Wir berechnen die Eigenvektoren.

$\mbf{\lambda_1:}$
\par 
\begin{align*}
   1x_1 + 2x_2 &= 0 \\
   -2x_1  -4x_2 &= 0 \\
   \Rightarrow x_1 = -2x_2
\end{align*}
$\Rightarrow \v{1} = \begin{pmatrix} -2 \\ 1 \end{pmatrix}$ oder irgendein Vielfaches. Der Eigenraum zu $\lambda_1$ ist
also der Spann von (die Gerade durch) $\v{1}$ oder $\{\mu \cdot \v{1} \mid \mu
\in \mathbb{K}\}$.

$\mbf{\lambda_2:}$
\par 
\begin{align*}
   4x_1 + 2x_2 &= 0 \\
   -2x_1 -1x_2 &= 0 \\
   \Rightarrow x_2 = -2x_1
\end{align*}
$\Rightarrow \v{2} = \begin{pmatrix} 1 \\ -2 \end{pmatrix}$. Der Eigenraum zu
   $\lambda_2$ ist $\{\mu \cdot \v{2} \mid \mu \in \mathbb{K}\}$

\subsection{$A_3$}

Es ist $\chi_{A_3}(\lambda) = det(A_3 - \lambda I) = 
\left|
\begin{pmatrix}
   -3-\lambda & -1 \\
   1 & -3 - \lambda
\end{pmatrix}
\right|= \lambda^2 +6\lambda + 10$. Die
pq-Formel liefert hierfür
\begin{align*}
   \lambda_{1,2} & = -3 \pm \sqrt{3 - 10} \\
   \intertext{Die Matrix hat also nur komplexe Eigenwerte.}
   \lambda_1     & = -3 + i                                        \\
   \lambda_2     & = -3 -i                                       \\
\end{align*}

Wir berechnen die Eigenvektoren.

$\mbf{\lambda_1:}$
\par 
\begin{align*}
   -ix_1  -x_2 &= 0 \\
   x_1  -ix_2 &= 0 \\
   \Rightarrow x_1 = ix_2
\end{align*}
$\Rightarrow \v{1} = \begin{pmatrix} i \\ 1 \end{pmatrix}$ oder irgendein
   Vielfaches. Der Eigenraum zu $\lambda_1$ ist also der Spann von (die Gerade
   durch) $\v{1}$ oder $\{\mu \cdot \v{1} \mid \mu \in \mathbb{K}\}$.

$\mbf{\lambda_2:}$
\par 
\begin{align*}
   ix_1  -x_2 &= 0 \\
   x1  + ix_2 &= 0 \\
   \Rightarrow x_2 = ix_1
\end{align*}
$\Rightarrow \v{2} = \begin{pmatrix} 1 \\ i \end{pmatrix}$. Der Eigenraum zu
   $\lambda_2$ ist $\{\mu \cdot \v{2} \mid \mu \in \mathbb{K}\}$

Es ist offensichtlich, dass für $A_1, A_2, A_3$ die beiden Eigenvektoren jeweils
linear unabhängig sind. Da es sich um $2\times 2$-Matrizen handelt, findet Satz
11.10 Anwendung und die Matrizen sind mit $P_i = \begin{pmatrix}\v{1}, \v{2}
\end{pmatrix}$ diagonalisierbar.

\section{}
\section{}
\subsection{}
Nach Satz 11.4 gilt $rang(A) < n$ genau dann, wenn $det(A) = 0$, nach Satz 11.9
sind die Eigenwerte die Zahlen $\lambda$ mit $det(A - \lambda I) = 0$. Folglich:
\begin{equation*}
   det(A) = 0 \Leftrightarrow rang(A) < n \Leftrightarrow rang(A - 0\cdot I) < n
\end{equation*}

\subsection{}
Es ist nach der Definition des Eigenwertes 
\begin{align*}
   A\v{} &= \lambda \v{} \\
   \intertext{für einen Vektor $\v{}\neq \mbf{0}$. Multiplikation mit $A$ gibt}
   A\cdot A \v{} &= A\cdot \lambda \v{} \\
   A^2 \v{} &= \lambda A \v{} \\
   A^2 \v{} &= \lambda \lambda \v{} \\
   A^2 \v{} &= \lambda^2 \v{}
\end{align*}
Dies lässt sich beliebig fortführen.

\end{document}
